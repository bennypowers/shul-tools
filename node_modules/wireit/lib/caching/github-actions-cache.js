/**
 * @license
 * Copyright 2022 Google LLC
 * SPDX-License-Identifier: Apache-2.0
 */
var __addDisposableResource = (this && this.__addDisposableResource) || function (env, value, async) {
    if (value !== null && value !== void 0) {
        if (typeof value !== "object" && typeof value !== "function") throw new TypeError("Object expected.");
        var dispose;
        if (async) {
            if (!Symbol.asyncDispose) throw new TypeError("Symbol.asyncDispose is not defined.");
            dispose = value[Symbol.asyncDispose];
        }
        if (dispose === void 0) {
            if (!Symbol.dispose) throw new TypeError("Symbol.dispose is not defined.");
            dispose = value[Symbol.dispose];
        }
        if (typeof dispose !== "function") throw new TypeError("Object not disposable.");
        env.stack.push({ value: value, dispose: dispose, async: async });
    }
    else if (async) {
        env.stack.push({ async: true });
    }
    return value;
};
var __disposeResources = (this && this.__disposeResources) || (function (SuppressedError) {
    return function (env) {
        function fail(e) {
            env.error = env.hasError ? new SuppressedError(e, env.error, "An error was suppressed during disposal.") : e;
            env.hasError = true;
        }
        function next() {
            while (env.stack.length) {
                var rec = env.stack.pop();
                try {
                    var result = rec.dispose && rec.dispose.call(rec.value);
                    if (rec.async) return Promise.resolve(result).then(next, function(e) { fail(e); return next(); });
                }
                catch (e) {
                    fail(e);
                }
            }
            if (env.hasError) throw env.error;
        }
        return next();
    };
})(typeof SuppressedError === "function" ? SuppressedError : function (error, suppressed, message) {
    var e = new Error(message);
    return e.name = "SuppressedError", e.error = error, e.suppressed = suppressed, e;
});
import * as pathlib from 'path';
import * as unbudgetedFs from 'fs/promises';
import * as fs from '../util/fs.js';
import * as https from 'https';
import { createHash } from 'crypto';
import { scriptReferenceToString } from '../config.js';
import { getScriptDataDir } from '../util/script-data-dir.js';
import '../util/dispose.js';
import { fileBudget } from '../util/fs.js';
import { execFile } from 'child_process';
import '../util/dispose.js';
/**
 * Caches script output to the GitHub Actions caching service.
 */
export class GitHubActionsCache {
    #baseUrl;
    #authToken;
    #logger;
    /**
     * Once we've hit a rate limit or service availability error, simply stop
     * hitting the cache for the remainder of this Wireit process. Caching is not
     * critical, it's just an optimization.
     *
     * TODO(aomarks) We could be a little smarter and do retries, but this at
     * least should stop builds breaking in the short-term.
     */
    #serviceIsDown = false;
    constructor(logger, baseUrl, authToken) {
        this.#baseUrl = baseUrl;
        this.#authToken = authToken;
        this.#logger = logger;
    }
    static create(logger) {
        // The ACTIONS_CACHE_URL and ACTIONS_RUNTIME_TOKEN environment variables are
        // automatically provided to GitHub Actions re-usable workflows. However,
        // they are _not_ provided to regular "run" scripts. For this reason, we
        // re-export those variables so that all "run" scripts can access them using
        // the "google/wireit@setup-github-actions-caching/v1" re-usable workflow.
        //
        // https://github.com/actions/toolkit/blob/500d0b42fee2552ae9eeb5933091fe2fbf14e72d/packages/cache/src/internal/cacheHttpClient.ts#L38
        const baseUrl = process.env['ACTIONS_CACHE_URL'];
        if (!baseUrl) {
            return {
                ok: false,
                error: {
                    reason: 'invalid-usage',
                    message: 'The ACTIONS_CACHE_URL variable was not set, but is required when ' +
                        'WIREIT_CACHE=github. Use the google/wireit@setup-github-cache/v1 ' +
                        'action to automatically set environment variables.',
                },
            };
        }
        if (!baseUrl.endsWith('/')) {
            // Internally, the @actions/cache library expects the URL to end with a
            // slash. While we could be more lenient, we want to match the behavior of
            // any other calls happening inside that library which we don't control.
            return {
                ok: false,
                error: {
                    reason: 'invalid-usage',
                    message: `The ACTIONS_CACHE_URL must end in a forward-slash, got ${JSON.stringify(baseUrl)}.`,
                },
            };
        }
        // https://github.com/actions/toolkit/blob/500d0b42fee2552ae9eeb5933091fe2fbf14e72d/packages/cache/src/internal/cacheHttpClient.ts#L63
        const authToken = process.env['ACTIONS_RUNTIME_TOKEN'];
        if (!authToken) {
            return {
                ok: false,
                error: {
                    reason: 'invalid-usage',
                    message: 'The ACTIONS_RUNTIME_TOKEN variable was not set, but is required when ' +
                        'WIREIT_CACHE=github. Use the google/wireit@setup-github-cache/v1 ' +
                        'action to automatically set environment variables.',
                },
            };
        }
        return {
            ok: true,
            value: new GitHubActionsCache(logger, baseUrl, authToken),
        };
    }
    async get(script, fingerprint) {
        const env_1 = { stack: [], error: void 0, hasError: false };
        try {
            if (this.#serviceIsDown) {
                return undefined;
            }
            const version = this.#computeVersion(fingerprint);
            const key = this.#computeCacheKey(script);
            const url = new URL('_apis/artifactcache/cache', this.#baseUrl);
            url.searchParams.set('keys', key);
            url.searchParams.set('version', version);
            const requestResult = __addDisposableResource(env_1, this.#request(url), false);
            const { req, resPromise } = requestResult;
            req.end();
            const result = await resPromise;
            if (!this.#maybeHandleServiceDown(result, script)) {
                return undefined;
            }
            const response = result.value;
            if (response.statusCode === /* No Content */ 204) {
                return undefined;
            }
            if (isOk(response)) {
                const { archiveLocation } = JSON.parse(await readBody(response));
                return new GitHubActionsCacheHit(script, archiveLocation, this.#logger);
            }
            throw new Error(`GitHub Cache check HTTP ${String(response.statusCode)} error: ` +
                (await readBody(response)));
        }
        catch (e_1) {
            env_1.error = e_1;
            env_1.hasError = true;
        }
        finally {
            __disposeResources(env_1);
        }
    }
    async set(script, fingerprint, absFiles) {
        const env_2 = { stack: [], error: void 0, hasError: false };
        try {
            if (this.#serviceIsDown) {
                return false;
            }
            const tempDir = __addDisposableResource(env_2, await makeTempDir(script), true);
            const tarballPath = await this.#makeTarball(absFiles.map((file) => file.path), tempDir.path);
            return await this.#reserveUploadAndCommitTarball(script, fingerprint, tarballPath);
        }
        catch (e_2) {
            env_2.error = e_2;
            env_2.hasError = true;
        }
        finally {
            const result_1 = __disposeResources(env_2);
            if (result_1)
                await result_1;
        }
    }
    /**
     * @returns True if we reserved, uploaded, and committed the tarball. False if
     * we gave up due to a rate limit error.
     * @throws If an unexpected HTTP error occured.
     */
    async #reserveUploadAndCommitTarball(script, fingerprint, tarballPath) {
        const tarballStats = await fs.stat(tarballPath);
        const tarballBytes = tarballStats.size;
        // Reference:
        // https://github.com/actions/toolkit/blob/f8a69bc473af4a204d0c03de61d5c9d1300dfb17/packages/cache/src/cache.ts#L174
        const GB = 1024 * 1024 * 1024;
        const maxBytes = 10 * GB;
        if (tarballBytes > maxBytes) {
            this.#logger.log({
                script,
                type: 'info',
                detail: 'cache-info',
                message: `Output was too big to be cached: ` +
                    `${Math.round(tarballBytes / GB)}GB > ` +
                    `${Math.round(maxBytes / GB)}GB.`,
            });
            return false;
        }
        const id = await this.#reserveCacheEntry(script, this.#computeCacheKey(script), this.#computeVersion(fingerprint), tarballBytes);
        // It's likely that we'll occasionally fail to reserve an entry and get
        // undefined here, especially when running multiple GitHub Action jobs in
        // parallel with the same scripts, because there is a window of time between
        // calling "get" and "set" on the cache in which another worker could have
        // reserved the entry before us. Non fatal, just don't save.
        if (id === undefined) {
            return false;
        }
        if (!(await this.#upload(script, id, tarballPath, tarballBytes))) {
            return false;
        }
        if (!(await this.#commit(script, id, tarballBytes))) {
            return false;
        }
        return true;
    }
    /**
     * @returns True if we uploaded, false if we gave up due to a rate limit error.
     * @throws If an unexpected HTTP error occured.
     */
    async #upload(script, id, tarballPath, tarballBytes) {
        const url = new URL(`_apis/artifactcache/caches/${id}`, this.#baseUrl);
        // Reference:
        // https://github.com/actions/toolkit/blob/500d0b42fee2552ae9eeb5933091fe2fbf14e72d/packages/cache/src/options.ts#L59
        const maxChunkSize = 32 * 1024 * 1024;
        // TODO: update to TypeScript 5.2 and use the new `using` syntax for the
        // budget object.
        const reservation = await fileBudget.reserve();
        const tarballHandle = await unbudgetedFs.open(tarballPath, 'r');
        let offset = 0;
        try {
            // TODO(aomarks) Chunks could be uploaded in parallel.
            while (offset < tarballBytes) {
                const env_3 = { stack: [], error: void 0, hasError: false };
                try {
                    const chunkSize = Math.min(tarballBytes - offset, maxChunkSize);
                    const start = offset;
                    const end = offset + chunkSize - 1;
                    offset += maxChunkSize;
                    const tarballChunkStream = await fs.createReadStream(tarballPath, {
                        fd: tarballHandle.fd,
                        start,
                        end,
                        autoClose: false,
                    });
                    const opts = {
                        method: 'PATCH',
                        headers: {
                            'content-type': 'application/octet-stream',
                            'content-range': `bytes ${start}-${end}/*`,
                        },
                    };
                    const requestResult = __addDisposableResource(env_3, this.#request(url, opts), false);
                    const { req, resPromise } = requestResult;
                    tarballChunkStream.pipe(req);
                    tarballChunkStream.on('close', () => {
                        req.end();
                    });
                    const result = await resPromise;
                    if (!this.#maybeHandleServiceDown(result, script)) {
                        return false;
                    }
                    const response = result.value;
                    if (!isOk(response)) {
                        throw new Error(`GitHub Cache upload HTTP ${String(response.statusCode)} error: ${await readBody(response)}\nopts: ${JSON.stringify(opts)}`);
                    }
                }
                catch (e_3) {
                    env_3.error = e_3;
                    env_3.hasError = true;
                }
                finally {
                    __disposeResources(env_3);
                }
            }
            return true;
        }
        finally {
            await tarballHandle.close();
            reservation[Symbol.dispose]();
        }
    }
    /**
     * @returns True if we committed, false if we gave up due to a rate limit error.
     * @throws If an unexpected HTTP error occured.
     */
    async #commit(script, id, tarballBytes) {
        const env_4 = { stack: [], error: void 0, hasError: false };
        try {
            const url = new URL(`_apis/artifactcache/caches/${String(id)}`, this.#baseUrl);
            const reqBody = JSON.stringify({
                size: tarballBytes,
            });
            const requestResult = __addDisposableResource(env_4, this.#request(url, {
                method: 'POST',
                headers: {
                    'content-type': 'application/json',
                },
            }), false);
            const { req, resPromise } = requestResult;
            req.end(reqBody);
            const result = await resPromise;
            if (!this.#maybeHandleServiceDown(result, script)) {
                return false;
            }
            const response = result.value;
            if (!isOk(response)) {
                throw new Error(`GitHub Cache commit HTTP ${String(response.statusCode)} error: ${await readBody(response)}`);
            }
            return true;
        }
        catch (e_4) {
            env_4.error = e_4;
            env_4.hasError = true;
        }
        finally {
            __disposeResources(env_4);
        }
    }
    #request(url, options) {
        return request(url, {
            ...options,
            headers: {
                // https://github.com/actions/toolkit/blob/500d0b42fee2552ae9eeb5933091fe2fbf14e72d/packages/cache/src/internal/cacheHttpClient.ts#L55
                accept: 'application/json;api-version=6.0-preview.1',
                // https://github.com/actions/toolkit/blob/500d0b42fee2552ae9eeb5933091fe2fbf14e72d/packages/http-client/src/auth.ts#L46
                authorization: `Bearer ${this.#authToken}`,
                ...options?.headers,
            },
        });
    }
    /**
     * If we received an error that indicates something is wrong with the GitHub
     * Actions service that is not our fault, log an error and return false.
     * Otherwise return true.
     */
    #maybeHandleServiceDown(res, script) {
        if (!res.ok) {
            if (!this.#serviceIsDown) {
                this.#logger.log({
                    script,
                    type: 'info',
                    detail: 'cache-info',
                    message: `Connection error from GitHub Actions service, caching disabled. ` +
                        'Detail: ' +
                        ('code' in res.error
                            ? `${res.error.code} `
                            : '') +
                        res.error.message,
                });
            }
        }
        else {
            switch (res.value.statusCode) {
                case /* Too Many Requests */ 429: {
                    if (!this.#serviceIsDown) {
                        this.#logger.log({
                            script,
                            type: 'info',
                            detail: 'cache-info',
                            message: `Hit GitHub Actions cache rate limit, caching disabled.`,
                        });
                    }
                    break;
                }
                case /* Service Unavailable */ 503: {
                    if (!this.#serviceIsDown) {
                        this.#logger.log({
                            script,
                            type: 'info',
                            detail: 'cache-info',
                            message: `GitHub Actions service is unavailable, caching disabled.`,
                        });
                    }
                    break;
                }
                default: {
                    return true;
                }
            }
        }
        this.#serviceIsDown = true;
        return false;
    }
    #computeCacheKey(script) {
        return createHash('sha256')
            .update(scriptReferenceToString(script))
            .digest('hex');
    }
    #computeVersion(fingerprint) {
        const parts = [
            fingerprint.string,
            'gzip',
            // The ImageOS environment variable tells us which operating system
            // version is being used for the worker VM (e.g. "ubuntu20",
            // "macos11"). We already include process.platform in the fingerprint,
            // but this is more specific.
            //
            // There is also an ImageVersion variable (e.g. "20220405.4") which we
            // could consider including, but it probably changes frequently and is
            // unlikely to affect output, so we prefer the higher cache hit rate.
            process.env.ImageOS ?? '',
            // Versioning salt:
            //   - <omitted>: Initial version.
            //   - 2: Removed empty directories manifest.
            '2',
        ];
        return createHash('sha256')
            .update(parts.join('\x1E'))
            .digest('hex');
    }
    /**
     * Create a tarball file in a local temp directory containing the given paths.
     *
     * @returns The full path to the tarball file on disk.
     */
    async #makeTarball(paths, tempDir) {
        // Create a manifest file so that we can pass a large number of files to
        // tar.
        const manifestPath = pathlib.join(tempDir, 'manifest.txt');
        await fs.writeFile(manifestPath, paths.join('\n'), 'utf8');
        const tarballPath = pathlib.join(tempDir, 'cache.tgz');
        await new Promise((resolve, reject) => {
            execFile('tar', [
                // Use the newer standardized tar format.
                '--posix',
                // Use gzip compression.
                //
                // TODO(aomarks) zstd is faster and has better performance, but it's
                // availability is unreliable, and appears to have a bug on Windows
                // (https://github.com/actions/cache/issues/301). Investigate and
                // enable if easy.
                '--gzip',
                '--create',
                '--file',
                tarballPath,
                // Use absolute paths (note we use the short form because the long
                // form is --absolute-names on GNU tar, but --absolute-paths on BSD
                // tar).
                '-P',
                // We have a complete list of files and directories, so we don't need
                // or want tar to automatically expand directories. This also allows
                // us to create empty directories, even if they aren't actually empty
                // on disk.
                '--no-recursion',
                '--files-from',
                manifestPath,
            ], (error) => {
                if (error != null) {
                    reject(`tar error: ${String(error)}`);
                }
                else {
                    resolve();
                }
            });
        });
        return tarballPath;
    }
    /**
     * Reserve a cache entry.
     *
     * @returns A numeric cache id the cache entry was reserved for us, or
     * undefined if the cache entry was already reserved, or a rate limit error
     * occured.
     */
    async #reserveCacheEntry(script, key, version, cacheSize) {
        const env_5 = { stack: [], error: void 0, hasError: false };
        try {
            const url = new URL('_apis/artifactcache/caches', this.#baseUrl);
            const reqBody = JSON.stringify({
                key,
                version,
                cacheSize,
            });
            const requestResult = __addDisposableResource(env_5, this.#request(url, {
                method: 'POST',
                headers: {
                    'content-type': 'application/json',
                },
            }), false);
            const { req, resPromise } = requestResult;
            req.end(reqBody);
            const result = await resPromise;
            if (!this.#maybeHandleServiceDown(result, script)) {
                return undefined;
            }
            const response = result.value;
            if (isOk(response)) {
                const resData = JSON.parse(await readBody(response));
                return resData.cacheId;
            }
            if (response.statusCode === /* Conflict */ 409) {
                return undefined;
            }
            throw new Error(`GitHub Cache reserve HTTP ${String(response.statusCode)} error: ${await readBody(response)}`);
        }
        catch (e_5) {
            env_5.error = e_5;
            env_5.hasError = true;
        }
        finally {
            __disposeResources(env_5);
        }
    }
}
class GitHubActionsCacheHit {
    #script;
    #url;
    #logger;
    #applied = false;
    constructor(script, location, logger) {
        this.#script = script;
        this.#url = location;
        this.#logger = logger;
    }
    async apply() {
        const env_6 = { stack: [], error: void 0, hasError: false };
        try {
            if (this.#applied) {
                throw new Error('GitHubActionsCacheHit.apply was called more than once');
            }
            this.#applied = true;
            const tempDir = __addDisposableResource(env_6, await makeTempDir(this.#script), true);
            const tarballPath = pathlib.join(tempDir.path, 'cache.tgz');
            try {
                await this.#download(tarballPath);
            }
            catch (e) {
                this.#logger.log({
                    type: 'info',
                    detail: 'cache-info',
                    script: this.#script,
                    message: `Failed to download GitHub Actions cache tarball: ${e?.message ?? String(e)}`,
                });
                // This is fine, it's as though there was nothing to restore from
                // the cache.
                return;
            }
            await this.#extract(tarballPath);
        }
        catch (e_6) {
            env_6.error = e_6;
            env_6.hasError = true;
        }
        finally {
            const result_2 = __disposeResources(env_6);
            if (result_2)
                await result_2;
        }
    }
    async #download(tarballPath) {
        const env_7 = { stack: [], error: void 0, hasError: false };
        try {
            const requestResult = __addDisposableResource(env_7, request(this.#url), false);
            const { req, resPromise } = requestResult;
            req.end();
            const result = await resPromise;
            if (!result.ok) {
                throw new Error(`GitHub Cache download TCP error`);
            }
            const response = result.value;
            if (!isOk(response)) {
                throw new Error(`GitHub Cache download HTTP ${String(response.statusCode)} error`);
            }
            const writeTarballStream = await fs.createWriteStream(tarballPath);
            await new Promise((resolve, reject) => {
                writeTarballStream.on('error', (error) => reject(error));
                response.on('error', (error) => reject(error));
                response.pipe(writeTarballStream);
                writeTarballStream.on('close', () => {
                    resolve();
                });
            });
        }
        catch (e_7) {
            env_7.error = e_7;
            env_7.hasError = true;
        }
        finally {
            __disposeResources(env_7);
        }
    }
    #extract(tarballPath) {
        return new Promise((resolve, reject) => {
            execFile('tar', ['--extract', '--file', tarballPath, '--gzip', '-P'], (error) => {
                if (error != null) {
                    reject(`tar error: ${String(error)}`);
                }
                else {
                    resolve();
                }
            });
        });
    }
}
function request(url, options) {
    const opts = {
        ...options,
        headers: {
            // https://github.com/actions/toolkit/blob/500d0b42fee2552ae9eeb5933091fe2fbf14e72d/packages/cache/src/internal/cacheHttpClient.ts#L67
            'user-agent': 'actions/cache',
            ...options?.headers,
        },
    };
    let req;
    const resPromise = new Promise((resolve) => {
        req = https.request(url, opts, (value) => {
            resolve({ ok: true, value });
        });
        req.on('error', (error) => {
            resolve({ ok: false, error });
        });
        req.on('socket', (socket) => {
            socket.on('error', () => {
                resolve({ ok: false, error: new Error('socket error') });
            });
            socket.on('close', (hadError) => {
                if (hadError) {
                    resolve({ ok: false, error: new Error('socket closed with error') });
                }
            });
        });
    });
    return {
        req,
        resPromise,
        [Symbol.dispose]() {
            req.destroy();
            req.socket?.destroy();
        },
    };
}
function isOk(res) {
    return (res.statusCode !== undefined &&
        res.statusCode >= 200 &&
        res.statusCode < 300);
}
function readBody(res) {
    const chunks = [];
    res.on('data', (chunk) => {
        chunks.push(chunk);
    });
    return new Promise((resolve, reject) => {
        res.on('error', (error) => {
            reject(error);
        });
        res.socket.on('error', () => {
            reject(new Error('socket error'));
        });
        res.socket.on('close', (hadError) => {
            if (hadError) {
                reject(new Error('socket closed with error'));
            }
        });
        res.on('end', () => {
            resolve(Buffer.concat(chunks).toString());
        });
    });
}
async function makeTempDir(script) {
    const path = await fs.mkdtemp(pathlib.join(getScriptDataDir(script), 'temp'));
    return {
        path,
        async [Symbol.asyncDispose]() {
            await fs.rm(path, { recursive: true });
        },
    };
}
//# sourceMappingURL=github-actions-cache.js.map